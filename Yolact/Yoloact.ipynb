{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yoloact.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "60r_P7_WXQK6"
      },
      "source": [
        "####"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPN8cTBfFIsg"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision.transforms.functional as F\n",
        "from torchvision.ops import nms , batched_nms"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbhoGgQu2bZv"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "import torchvision.transforms.functional as F\n",
        "from tqdm.notebook import tqdm\n",
        "from torchvision.ops import roi_align"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgjRg3GZ2fFo"
      },
      "source": [
        "def iou_width_height(boxes1, boxes2):\n",
        "\n",
        "    intersection = torch.min(boxes1[..., 0], boxes2[..., 0]) * torch.min(\n",
        "        boxes1[..., 1], boxes2[..., 1]\n",
        "    )\n",
        "    union = (\n",
        "        boxes1[..., 0] * boxes1[..., 1] + boxes2[..., 0] * boxes2[..., 1] - intersection\n",
        "    )\n",
        "    return intersection / union"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6WrEEvt2hZ1"
      },
      "source": [
        "def show_tensor_images(image_tensor, num_images=2, size=(3 , 550 , 550)):\n",
        "    image_shifted = image_tensor\n",
        "    image_unflat = image_shifted.detach().cpu().view(-1, *size)\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.show()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7lqyOQT33lz"
      },
      "source": [
        "def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n",
        "\n",
        "    if box_format == \"midpoint\":\n",
        "        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n",
        "        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n",
        "        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n",
        "        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n",
        "        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n",
        "        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n",
        "        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n",
        "        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n",
        "\n",
        "    if box_format == \"corners\":\n",
        "        box1_x1 = boxes_preds[..., 0:1]\n",
        "        box1_y1 = boxes_preds[..., 1:2]\n",
        "        box1_x2 = boxes_preds[..., 2:3]\n",
        "        box1_y2 = boxes_preds[..., 3:4]\n",
        "        box2_x1 = boxes_labels[..., 0:1]\n",
        "        box2_y1 = boxes_labels[..., 1:2]\n",
        "        box2_x2 = boxes_labels[..., 2:3]\n",
        "        box2_y2 = boxes_labels[..., 3:4]\n",
        "\n",
        "    x1 = torch.max(box1_x1, box2_x1)\n",
        "    y1 = torch.max(box1_y1, box2_y1)\n",
        "    x2 = torch.min(box1_x2, box2_x2)\n",
        "    y2 = torch.min(box1_y2, box2_y2)\n",
        "\n",
        "    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
        "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
        "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
        "\n",
        "    return intersection / (box1_area + box2_area - intersection + 1e-6)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05XaC4lsNUor"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfAHeaY2NBsK"
      },
      "source": [
        "\n",
        "class Conv(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 out_channels , \n",
        "                 kernel_size = (3 , 3) , \n",
        "                 stride = (1 , 1) , \n",
        "                 padding = 1 , \n",
        "                 use_norm = True , \n",
        "                 use_activation = True , \n",
        "                 use_dropout = False):\n",
        "        super(Conv , self).__init__()\n",
        "\n",
        "        self.use_norm = use_norm\n",
        "        self.use_activation = use_activation\n",
        "        self.use_dropout = use_dropout\n",
        "        self.conv1 = nn.Conv2d(in_channels , \n",
        "                               out_channels , \n",
        "                               kernel_size , \n",
        "                               stride , \n",
        "                               padding)\n",
        "        if self.use_norm:\n",
        "            self.norm = nn.BatchNorm2d(out_channels)\n",
        "        if self.use_activation:\n",
        "            self.activation = nn.ReLU(inplace=False)\n",
        "        if self.use_dropout:\n",
        "            self.dropout = nn.Dropout()\n",
        "\n",
        "    def forward(self , x):\n",
        "        x = self.conv1(x)\n",
        "        if self.use_norm:\n",
        "            x = self.norm(x)\n",
        "        if self.use_activation:\n",
        "            x = self.activation(x)\n",
        "        if self.use_dropout:\n",
        "            x = self.dropout(x)\n",
        "        return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUorTjg_Tyux"
      },
      "source": [
        "\n",
        "class ConvT(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 out_channels , \n",
        "                 kernel_size = (2 , 2) , \n",
        "                 stride = (2 , 2) , \n",
        "                 padding = 0 , \n",
        "                 use_norm = True , \n",
        "                 use_activation = True):\n",
        "        super(ConvT , self).__init__()\n",
        "\n",
        "        self.use_norm = use_norm\n",
        "        self.use_activation = use_activation\n",
        "\n",
        "        self.convT = nn.ConvTranspose2d(in_channels , \n",
        "                                        out_channels , \n",
        "                                        kernel_size , \n",
        "                                        stride ,\n",
        "                                        padding)\n",
        "        if self.use_norm:\n",
        "            self.norm = nn.InstanceNorm2d(out_channels)\n",
        "        if self.use_activation:\n",
        "            self.activation = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self , x):\n",
        "        x = self.convT(x)\n",
        "        if self.use_norm:\n",
        "            x = self.norm(x)\n",
        "        if self.use_activation:\n",
        "            x = self.activation(x)\n",
        "        return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PQq9zC3NaiB"
      },
      "source": [
        "class Resnet_Block(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 out_channels , \n",
        "                 downsample = False):\n",
        "        super(Resnet_Block , self).__init__()\n",
        "\n",
        "        self.downsample = downsample\n",
        "\n",
        "        if self.downsample:\n",
        "            self.conv1 = Conv(in_channels , \n",
        "                        in_channels , \n",
        "                        kernel_size=(2 , 2) , \n",
        "                        stride=(2 , 2) ,\n",
        "                        padding = 0)\n",
        "            \n",
        "            self.conv_skip = Conv(in_channels ,\n",
        "                            out_channels ,\n",
        "                            kernel_size = (2 ,2) , \n",
        "                            stride = (2 , 2) , \n",
        "                            padding = 0)\n",
        "        else:    \n",
        "            self.conv1 = Conv(in_channels , \n",
        "                            in_channels , \n",
        "                            kernel_size=(1 , 1) , \n",
        "                            stride=(1 , 1) ,\n",
        "                            padding = 0)\n",
        "            \n",
        "            self.conv_skip = Conv(in_channels ,\n",
        "                              out_channels ,\n",
        "                              kernel_size = (1 , 1) , \n",
        "                              stride = (1 ,1) , \n",
        "                              padding = 0)\n",
        "            \n",
        "        self.conv2 = Conv(in_channels , \n",
        "                          in_channels)\n",
        "        \n",
        "        self.conv3 = Conv(in_channels , \n",
        "                          out_channels , \n",
        "                          kernel_size = (1 , 1) , \n",
        "                          stride = (1 , 1) , \n",
        "                          padding = 0)\n",
        "        \n",
        "\n",
        "        \n",
        "    def forward(self , x): \n",
        "        x_ = x.clone()\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x_ = self.conv_skip(x_)\n",
        "        x += x_\n",
        "        return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YENyYadNd4H"
      },
      "source": [
        "\n",
        "class Linear(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 out_channels):\n",
        "        super(Linear , self).__init__()\n",
        "        self.linear1 = nn.Linear(in_channels , out_channels)\n",
        "        self.softmax = nn.Softmax(dim = 1)\n",
        "\n",
        "    def forward(self , x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V02c6YmNgW3"
      },
      "source": [
        "class Resnet(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 out_channels):\n",
        "        super(Resnet , self).__init__()\n",
        "\n",
        "        self.conv1 = Conv(in_channels , 64 , kernel_size=(7 , 7) , stride=(2 , 2) , padding=3)\n",
        "\n",
        "        self.conv2 = self._make_repeated_blocks(64 , 256 , 3 , downsample = False)\n",
        "        self.conv3 = self._make_repeated_blocks(256 , 512 , 4)\n",
        "        self.conv4 = self._make_repeated_blocks(512 , 1024 , 6)\n",
        "        self.conv5 = self._make_repeated_blocks(1024 , 2048 , 3)\n",
        "        self.linear = Linear(2048 , out_channels)\n",
        "\n",
        "    def _make_repeated_blocks(self , in_channels , out_channels , repeats , downsample = True):\n",
        "        layers = []\n",
        "        for i in range(repeats):\n",
        "            if i == 0 and downsample == True:\n",
        "                layers.append(Resnet_Block(in_channels , out_channels , downsample=downsample))\n",
        "            elif i == 0:\n",
        "                layers.append(Resnet_Block(in_channels , out_channels))\n",
        "            else:\n",
        "                layers.append(Resnet_Block(out_channels , out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self , x):\n",
        "        x_out = []\n",
        "        x = self.conv1(x)\n",
        "        x = torch.max_pool2d(x , kernel_size = (2 , 2) , stride = (2 , 2))\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x_out.append(x)\n",
        "        x = self.conv4(x)\n",
        "        x_out.append(x)\n",
        "        x = self.conv5(x)\n",
        "        x_out.append(x)\n",
        "        return x_out"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Iki4K_wNiYX"
      },
      "source": [
        "'''def test():\n",
        "    resnet = Resnet(3 , 1000).to(device)\n",
        "    x = torch.randn(2 , 3 , 550 , 550).to(device)\n",
        "    z = resnet(x)\n",
        "    for z_ in z:\n",
        "        print(z_.shape)\n",
        "test()'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0N51o3GQ7It"
      },
      "source": [
        "class Concat_Block(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Concat_Block , self).__init__()\n",
        "        b = 5\n",
        "    def forward(self , x):\n",
        "        return x"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZyudRUDTK7o"
      },
      "source": [
        "config_top = [\n",
        "              256 , \n",
        "              256 , \n",
        "              256\n",
        "]\n",
        "\n",
        "config_down = [\n",
        "               'C' , \n",
        "               1024 , \n",
        "               'C' , \n",
        "               256 , \n",
        "]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drBU7CLIfjwK"
      },
      "source": [
        "class FPN(nn.Module):\n",
        "    def __init__(self , \n",
        "                 config_top=config_top , \n",
        "                 config_down=config_down , \n",
        "                 in_channels_ = 2048):\n",
        "        super(FPN , self).__init__()\n",
        "\n",
        "        self.top_layers = nn.ModuleList()\n",
        "        self.down_layers = nn.ModuleList()\n",
        "\n",
        "        in_channels = in_channels_\n",
        "        for layer in config_top:\n",
        "            out_channels = layer\n",
        "            self.top_layers.append(\n",
        "                Conv(in_channels , out_channels , kernel_size=(3 , 3) , stride=(1 , 1) , padding = 1)\n",
        "            )\n",
        "            in_channels = out_channels\n",
        "        in_channels = in_channels_\n",
        "        for i , layer in enumerate(config_down):\n",
        "            if isinstance(layer , str):\n",
        "                self.down_layers.append(Concat_Block())\n",
        "            else:\n",
        "                \n",
        "                if i == 0:\n",
        "                    out_channels = layer\n",
        "                    self.down_layers.append(\n",
        "                        ConvT(in_channels , out_channels)\n",
        "                    )\n",
        "                    in_channels = out_channels\n",
        "                else :\n",
        "                    out_channels = layer\n",
        "                    self.down_layers.append(\n",
        "                        ConvT(in_channels * 2  , out_channels)\n",
        "                    )\n",
        "                    in_channels = out_channels\n",
        "\n",
        "    def forward(self , x_list):\n",
        "        x_top , x_down = x_list[-1] , x_list[-1]\n",
        "        i = len(x_list)-1\n",
        "        for layer in self.top_layers:\n",
        "            x_top = layer(x_top)\n",
        "\n",
        "        for layer in self.down_layers:\n",
        "            x_down = layer(x_down)\n",
        "            if isinstance(layer , Concat_Block):\n",
        "                x_ = F.resize(x_list[i] , (x_down.shape[-1] , x_down.shape[-1]))\n",
        "                #print(x_down.shape , x_.shape)\n",
        "                x_down = torch.cat([x_down , x_] , dim=1)\n",
        "                i -= 1\n",
        "            #print(x_down.shape)\n",
        "        return x_top , x_down"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkvvAZmaheQB"
      },
      "source": [
        "'''def test():\n",
        "    resnet = Resnet(3 , 1000).to(device)\n",
        "    fpn = FPN().to(device)\n",
        "    x = torch.randn(2 , 3 , 550 , 550).to(device)\n",
        "    z = resnet(x)\n",
        "    x_top , x_down = fpn(z)\n",
        "    print(x_top.shape , x_down.shape)\n",
        "test()'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atSzjftrpWrg"
      },
      "source": [
        "class Protnet(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels = 512 , \n",
        "                 k_ = 4 , \n",
        "                 a = 5):\n",
        "        super(Protnet , self).__init__()\n",
        "\n",
        "        k = a * k_\n",
        "        self.layers = nn.ModuleList()\n",
        "        config_mask = [\n",
        "                    # [out_channels , repeats]\n",
        "                    [256 , 3] , \n",
        "                    256 , \n",
        "                    [k , 1]\n",
        "        ]\n",
        "\n",
        "        for layer in config_mask:\n",
        "            if isinstance(layer , list):\n",
        "                out_channels , repeats = layer\n",
        "                self.layers.append(Conv(in_channels , out_channels))\n",
        "                in_channels = out_channels\n",
        "\n",
        "            elif isinstance(layer , int):\n",
        "                out_channels = layer\n",
        "                self.layers.append(\n",
        "                    ConvT(in_channels , out_channels)\n",
        "                )\n",
        "        self.k = k_\n",
        "        self.a = a\n",
        "    def forward(self , x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x.view(x.shape[0] , x.shape[2] , x.shape[3] , self.a , self.k)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvWnES6CqVjR"
      },
      "source": [
        "'''x = torch.randn(2 , 512 , 68 , 68).to(device)\n",
        "protnet = Protnet().to(device)\n",
        "z = protnet(x)\n",
        "z.shape'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFq_rsIhqhZ4"
      },
      "source": [
        "class Head(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels = 512 , \n",
        "                 k=4 , \n",
        "                 a = 5 , \n",
        "                 c = 20):\n",
        "        super(Head , self).__init__()\n",
        "        hidden_dim = 256\n",
        "        self.conv1 = ConvT(in_channels , hidden_dim)\n",
        "        self.conv2 = ConvT(hidden_dim , hidden_dim)\n",
        "\n",
        "        self.conv3 = Conv(hidden_dim , c * a + 4 * a + k * a)\n",
        "\n",
        "        self.c = c\n",
        "        self.a = a\n",
        "        self.k = k\n",
        "\n",
        "        self.upsample = nn.Upsample(scale_factor=2)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self , x):\n",
        "        i = 0\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        class_index = self.c * self.a\n",
        "        bbox_index = 4 * self.a\n",
        "        mask_index = self.k * self.a\n",
        "        #print(class_index , bbox_index , mask_index)\n",
        "        #print(class_index + bbox_index + mask_index)\n",
        "        x_classes = x[:,:i+class_index , : , :]\n",
        "        i += class_index\n",
        "        x_bbox = x[: , class_index:i+bbox_index , : , :]\n",
        "        i += mask_index\n",
        "        x_mask = x[: , class_index+bbox_index:i+mask_index , : , :]\n",
        "        x_mask = self.tanh(self.upsample(x_mask))\n",
        "\n",
        "        return x_classes.view(x_classes.shape[0] , x_classes.shape[2] , x_classes.shape[3] , self.a , self.c) , x_bbox.view(x_bbox.shape[0] , x_bbox.shape[2] , x_bbox.shape[3] , self.a , 4) , x_mask.view(x_mask.shape[0] , x_mask.shape[2] , x_mask.shape[3] , self.a , self.k)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhDX4im16cfC"
      },
      "source": [
        "'''x = torch.randn(2 , 512 , 17 , 17).to(device)\n",
        "head = Head().to(device)\n",
        "z = head(x)\n",
        "classes , bbox , mask = z\n",
        "print(classes.shape , bbox.shape , mask.shape)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-5-Yi8OnZXp"
      },
      "source": [
        "class NMS(nn.Module):\n",
        "    def __init__(self , \n",
        "                 k = 4 , \n",
        "                 a = 5 , \n",
        "                 iou_threshold = 0.5):\n",
        "        super(NMS , self).__init__()\n",
        "\n",
        "        self.k = k\n",
        "        self.iou_threshold = iou_threshold\n",
        "        self.a = a\n",
        "\n",
        "    def _get_top_k(self , flatten_tensor , sorted_tensors):\n",
        "        out = []\n",
        "        k_ = self.k * self.a\n",
        "        #print(flatten_tensor.shape , sorted_tensors.shape)\n",
        "        sorted_top_k = sorted_tensors[:k_]\n",
        "        #print(sorted_top_k.shape)\n",
        "        for idx in sorted_top_k:\n",
        "            out.append(flatten_tensor[idx , :])\n",
        "        return torch.stack(out)\n",
        "\n",
        "\n",
        "    def forward(self , x , y):\n",
        "        '''\n",
        "        x => classes => [N , 68 , 68 , 5 , 20]\n",
        "        y => bbox    => [N , 68 , 68 , 5 , 4]\n",
        "        '''\n",
        "        out = []\n",
        "        final_classes = []\n",
        "        final_bbox = []\n",
        "        x = torch.argmax(x , dim=-1) # [N , 68 , 68 , 5]\n",
        "        x_flatten = torch.flatten(x.float() , start_dim=1 , end_dim=-1) # [N , x ]\n",
        "        y_flatten = torch.flatten(y , start_dim=1 , end_dim = -2) # [N , x , 4]\n",
        "        \n",
        "        for i in range(x.shape[0]):\n",
        "            #print(x_flatten[i].shape , y_flatten[i].shape)\n",
        "            nms_ = nms(y_flatten[i] , x_flatten[i] , self.iou_threshold)\n",
        "            out.append(torch.tensor(nms_))\n",
        "        for i in range(x.shape[0]):\n",
        "            final_classes.append(self._get_top_k(x_flatten[i].unsqueeze(-1) , out[i]))\n",
        "            final_bbox.append(self._get_top_k(y_flatten[i] , out[i]))\n",
        "        final_bbox = torch.stack(final_bbox)\n",
        "        final_classes = torch.stack(final_classes)\n",
        "        return final_bbox.view(final_bbox.shape[0] , self.a , self.k , 4) , final_classes.view(final_classes.shape[0] , self.a , self.k , 1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZtBwDLdfTyv"
      },
      "source": [
        "'''x = torch.randn(2 , 68 , 68 , 5 , 20)\n",
        "y = torch.randn(2 , 68 , 68 , 5 , 4)\n",
        "nms_ = NMS()\n",
        "final_bbox , final_classes = nms_(x , y)\n",
        "final_bbox.shape , final_classes.shape'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kz-2x3MQeu3z"
      },
      "source": [
        "class Yolact(nn.Module):\n",
        "    def __init__(self , \n",
        "                 k = 4 , \n",
        "                 a = 5 , \n",
        "                 c = 1):\n",
        "        super(Yolact , self).__init__()\n",
        "\n",
        "        self.backbone = Resnet(3 , 1000)\n",
        "        self.fpn = FPN()\n",
        "        self.protnet = Protnet(k_ = k , a = a , in_channels=256)\n",
        "        self.head = Head(k=k , a=a , c=c , in_channels=256)\n",
        "        self.nms = NMS(k=k , a=a)\n",
        "\n",
        "    def forward(self , x):\n",
        "        x = self.backbone(x)\n",
        "        x_top , x_down = self.fpn(x)\n",
        "        classes , bbox , mask = self.head(x_top)\n",
        "        prototypes = self.protnet(x_down)\n",
        "        #bbox , classes = self.nms(classes , bbox)\n",
        "        masks = prototypes + mask\n",
        "        #print(prototypes.shape , bbox.shape , classes.shape , mask.shape)\n",
        "        #print(masks.shape)\n",
        "        classes = torch.argmax(classes , dim=-1)\n",
        "        return classes.float().unsqueeze(-1) , bbox , masks"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4fu68OIs1Os"
      },
      "source": [
        "yolact = Yolact().to(device)\n",
        "x = torch.randn(2 , 3 , 550 , 550)\n",
        "classes , bbox , masks = yolact(x) \n",
        "print(classes.shape , bbox.shape , masks.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imZuVOYxs_Gj"
      },
      "source": [
        "class Dataset_(torch.utils.data.Dataset):\n",
        "    def __init__(self ,\n",
        "                 img_dir , \n",
        "                 label_dir , \n",
        "                 csv_file , \n",
        "                 anchors , \n",
        "                 transforms = None , \n",
        "                 S = 68 , \n",
        "                 B = 5 , \n",
        "                 C = 20):\n",
        "        super(Dataset_ , self).__init__()\n",
        "\n",
        "        self.img_dir = img_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.anchors = torch.from_numpy(np.array(anchors))\n",
        "        #print(self.anchors)\n",
        "        self.transforms = transforms\n",
        "        self.number_of_anchors_per_cell = 5\n",
        "        self.ignore_iou_thresh = 0.5\n",
        "        self.C = C\n",
        "        self.S = S\n",
        "        self.B = B\n",
        "        self.mask_size = 136\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self , idx):\n",
        "        img_size = 550\n",
        "        label_path = os.path.join(self.label_dir , self.df.iloc[idx , 1])\n",
        "        boxes = []\n",
        "        binary_mask = []\n",
        "        label_mask = []\n",
        "\n",
        "        img_path = os.path.join(self.img_dir , self.df.iloc[idx , 0])\n",
        "        image = np.asarray(plt.imread(img_path))\n",
        "        image = torch.from_numpy(image).permute(2 , 0 , 1)\n",
        "        transform_mask = transforms.Compose([\n",
        "                                             transforms.ToPILImage() , \n",
        "                                             transforms.Resize((5 , 5)) , \n",
        "                                             transforms.Grayscale() , \n",
        "                                             transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "        with open(label_path) as f:\n",
        "            for label in f.readlines():\n",
        "                class_label , x , y , width , height = [\n",
        "                    float(x) if float(x) != int(float(x)) else int(x)\n",
        "                    for x in label.replace(\"\\n\", \"\").split()\n",
        "                ]\n",
        "                boxes.append([ x , y , width , height , class_label])\n",
        "\n",
        "        #label_mask = torch.tensor(label_mask)\n",
        "        boxes = torch.tensor(boxes) \n",
        "        #binary_mask = torch.stack(binary_mask)\n",
        "\n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        targets = torch.zeros((self.B , self.S , self.S , 5))\n",
        "        target_mask = torch.zeros((self.B , self.mask_size , self.mask_size , 1))\n",
        "        for box in boxes:\n",
        "            iou_anchors = iou_width_height(box[2:4] , self.anchors)\n",
        "            anchors_indices = iou_anchors.argsort(descending=True, dim=0)        \n",
        "            x , y , width , height , class_label = box\n",
        "            has_anchor = [False for _ in range(self.B)]\n",
        "            for anchor_idx in anchors_indices:\n",
        "                anchor_on_scale = anchor_idx % self.B\n",
        "                S = self.S\n",
        "                i , j = int(S * y) , int(S * x)\n",
        "                anchor_taken = targets[anchor_on_scale , i , j , 0]\n",
        "                if not anchor_taken and not has_anchor[anchor_on_scale]:\n",
        "                    targets[anchor_on_scale , i , j , 0] = 1\n",
        "                    x_cell , y_cell = S * x - j , S * y - i\n",
        "                    width_cell , height_cell = (\n",
        "                        width * S , \n",
        "                        height * S\n",
        "                    )\n",
        "                    box_coordinate = torch.tensor([x_cell , y_cell , width_cell , height_cell])\n",
        "                    targets[anchor_on_scale , i , j , :4] = box_coordinate\n",
        "                    targets[anchor_on_scale , i , j , 4] = int(class_label)\n",
        "                    target_mask_ = F.crop(image , int(x_cell) , int(y_cell) , int(width_cell) , int(height_cell))\n",
        "                    target_mask_ = transform_mask(target_mask_)\n",
        "                    #print(target_mask_.permute(1 , 2 , 0).shape)\n",
        "                    #print(target_mask[anchor_on_scale , i:i+5 , j:j+5 , 0:1].shape)\n",
        "                    target_mask[anchor_on_scale , i:i+5 , j:j+5 , 0:1] = target_mask_.permute(1 , 2 , 0)\n",
        "                    target_mask[anchor_on_scale , i:i+5 , j:j+5 , 1:2] = int(class_label)\n",
        "                    has_anchor[anchor_on_scale] = True\n",
        "                elif not anchor_taken and iou_anchors[anchor_idx] > self.ignore_iou_thresh:\n",
        "                    targets[anchor_on_scale , i , j , 0] = -1\n",
        "        return image , targets.view(self.S , self.S , self.B , 5) , target_mask.view(self.mask_size , self.mask_size , self.B , 1)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lantYaAe38QF"
      },
      "source": [
        "anchors = [[ 0.28, 0.22], [  0.38, 0.48], [ 0.9, 0.78], [ 0.07, 0.15], [ 0.15, 0.11]]\n",
        "transform = transforms.Compose([\n",
        "                                transforms.ToPILImage() , \n",
        "                                transforms.Resize((550 , 550)) , \n",
        "                                transforms.ToTensor()\n",
        "])\n",
        "dataset = Dataset_(\n",
        "    img_dir = '/content/drive/MyDrive/Yolo_Dataset/images/' , \n",
        "    label_dir = '/content/drive/MyDrive/Yolo_Dataset/labels' , \n",
        "    csv_file = '/content/drive/MyDrive/Yolo_Dataset/train.csv' , \n",
        "    anchors = anchors , \n",
        "    transforms = transform\n",
        ")\n",
        "dataloader = torch.utils.data.DataLoader(dataset , batch_size = 1 , shuffle=True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4zf9EtU4Bdr"
      },
      "source": [
        "for x , y , z in dataloader:\n",
        "    show_tensor_images(x)\n",
        "    print(y.shape)\n",
        "    print(z.shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAGWLm_D4Dzz"
      },
      "source": [
        "adv_criterion = nn.BCEWithLogitsLoss()\n",
        "recon_criterion = nn.L1Loss()\n",
        "ce_criterion = nn.CrossEntropyLoss()\n",
        "lambda_recon = 200\n",
        "betas = (0.5 , 0.999)\n",
        "\n",
        "\n",
        "n_epochs = 200\n",
        "display_steps = 1\n",
        "lr = 0.002"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19lHB86zbabZ"
      },
      "source": [
        "yolact = Yolact().to(device)\n",
        "opt = torch.optim.Adam(yolact.parameters() , lr=lr , betas=betas)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQtqn3tdbjST"
      },
      "source": [
        "def train():\n",
        "    mean_yolact_loss = 0\n",
        "    cur_step = 0\n",
        "    for epoch in range(n_epochs):\n",
        "        for img , label ,  mask_label in dataloader:\n",
        "            img , label , mask_label = img.to(device) , label.to(device)  , mask_label.to(device)\n",
        "\n",
        "            opt.zero_grad()\n",
        "            cls_ , bbox , mask  = yolact(img)\n",
        "            #print(cls.shape , bbox.shape) # label => [N , 68 , 68 , 5 , 5]\n",
        "                                           # mask_label => [N , 136 , 136 , 5 , 4]\n",
        "                                           # cls_ => [N , 68  ,68 , 5 , 20] \n",
        "                                           # bbox => [N , 68 , 68 , 5 , 4]\n",
        "                                           # mask => [N , 136 , 136 , 5 , 4]\n",
        "\n",
        "            loss_1 = recon_criterion(cls_ , label[... , 4:5])\n",
        "            loss_2 = recon_criterion(mask , mask_label)\n",
        "            loss_3 = recon_criterion(bbox , label[... , :4])\n",
        "\n",
        "            loss = (loss_1 + loss_2 + loss_3) / 3\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            mean_yolact_loss += loss.item() / display_steps\n",
        "            if cur_step % display_steps == 0:\n",
        "                print(f'Epoch {epoch} , Step {cur_step} , Mean Yolact Loss {mean_yolact_loss}')\n",
        "            cur_step +=1\n",
        "        mean_yolact_loss = 0"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoqKhbcRc2Cw"
      },
      "source": [
        "train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EjFbUfrc2fz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}